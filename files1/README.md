# RNN-Based Fileless Malware Detection System
## Ubuntu Installation & Usage Guide

A comprehensive RNN implementation for detecting fileless malware using behavioral and system-level features. Trains and compares 4 different architectures: Simple RNN, LSTM, GRU, and Bidirectional LSTM.

---

## üöÄ Quick Start

```bash
# 1. Clone or extract this package
cd rnn-malware-detection

# 2. Run the automated setup script
chmod +x setup.sh
./setup.sh

# 3. Place your datasets in the data/ directory

# 4. Run the analysis
python3 rnn_fileless_malware_detection.py
```

---

## üìã Requirements

### System Requirements
- **OS:** Ubuntu 18.04+ (tested on Ubuntu 20.04/22.04/24.04)
- **Python:** 3.8 or higher
- **RAM:** 4GB minimum, 8GB recommended
- **Disk Space:** 2GB free space
- **CPU:** Any modern multi-core processor (GPU optional)

### Python Packages
All dependencies are listed in `requirements.txt`:
- TensorFlow 2.13+
- pandas
- numpy
- matplotlib
- seaborn
- scikit-learn
- openpyxl

---

## üîß Installation

### Method 1: Automated Setup (Recommended)

```bash
chmod +x setup.sh
./setup.sh
```

This will:
- Check Python version
- Create a virtual environment
- Install all dependencies
- Create necessary directories
- Verify installation

### Method 2: Manual Setup

```bash
# 1. Ensure Python 3.8+ is installed
python3 --version

# 2. Install pip if not present
sudo apt update
sudo apt install -y python3-pip python3-venv

# 3. Create virtual environment
python3 -m venv venv
source venv/bin/activate

# 4. Install dependencies
pip install --upgrade pip
pip install -r requirements.txt

# 5. Create directories
mkdir -p data outputs logs
```

---

## üìÇ Directory Structure

```
rnn-malware-detection/
‚îú‚îÄ‚îÄ rnn_fileless_malware_detection.py  # Main script
‚îú‚îÄ‚îÄ requirements.txt                    # Python dependencies
‚îú‚îÄ‚îÄ setup.sh                           # Automated setup script
‚îú‚îÄ‚îÄ README.md                          # This file
‚îú‚îÄ‚îÄ ANALYSIS_REPORT.md                 # Example analysis report
‚îú‚îÄ‚îÄ data/                              # Place your datasets here
‚îÇ   ‚îú‚îÄ‚îÄ newDataset.csv                 # Main dataset (CSV)
‚îÇ   ‚îî‚îÄ‚îÄ new_malware_samples.xlsx       # Additional samples (Excel)
‚îú‚îÄ‚îÄ outputs/                           # Generated results
‚îÇ   ‚îú‚îÄ‚îÄ *.png                         # Visualizations
‚îÇ   ‚îú‚îÄ‚îÄ model_comparison.csv          # Performance metrics
‚îÇ   ‚îî‚îÄ‚îÄ ANALYSIS_REPORT.md            # Detailed report
‚îî‚îÄ‚îÄ venv/                             # Virtual environment (created by setup)
```

---

## üìä Dataset Format

### CSV Dataset (newDataset.csv)
Your CSV file should have the following structure:

```csv
Name,Label,handles_num,hiveList,dlls_ldrmodules_num,...
Baseline,1,100,568,2635,...
Malware_Sample_1,0,95,450,1800,...
```

**Required Columns:**
- `Name` - Sample name/identifier
- `Label` - Binary label (1 = Benign, 0 = Malicious)
- 33 feature columns (behavioral and system indicators)

**Feature Categories:**
1. **Process Information:** handles_num, modules_num, processes_*
2. **DLL Analysis:** dlls_ldrmodules_*, dlls_dlllist_*
3. **Registry Events:** total_reg_events, read_events, write_events, del_events
4. **Network Activity:** tcp/udp_connections, http(s)_requests, dns_requests
5. **System Artifacts:** mutex_mutantscan_num, threads_thrdscan_num, callbacks_num

### Excel Dataset (Optional)
Additional malware samples in Excel format with the same column structure.

---

## üéØ Usage

### Basic Usage

```bash
# Activate virtual environment
source venv/bin/activate

# Run with default settings
python3 rnn_fileless_malware_detection.py
```

### Advanced Usage

You can modify the script to customize parameters:

```python
# Open rnn_fileless_malware_detection.py and edit the main() function:

# Change dataset paths
df = classifier.load_and_combine_data(
    csv_path='data/your_dataset.csv',
    excel_path='data/your_excel_file.xlsx'
)

# Modify train/test split
classifier.preprocess_data(df, test_size=0.2, random_state=42)

# Adjust training parameters
classifier.train_model(
    model_type='gru',
    epochs=150,          # More epochs
    batch_size=16,       # Larger batch size
    units=128,           # More units
    dropout=0.4,         # Higher dropout
    patience=20          # More patience
)
```

### Training Specific Models

Edit the `model_types` list in `main()`:

```python
# Train only GRU
model_types = ['gru']

# Train only LSTM and GRU
model_types = ['lstm', 'gru']

# Train all models (default)
model_types = ['simple_rnn', 'lstm', 'gru', 'bidirectional_lstm']
```

---

## üìà Output Files

After running, check the `outputs/` directory:

### Visualizations
1. **model_comparison.png** - Bar charts comparing all models across 5 metrics
2. **roc_curves_comparison.png** - ROC curves showing model discrimination
3. **confusion_matrix_[model].png** - Confusion matrices for each model
4. **training_history_[model].png** - Training/validation curves for each model

### Data Files
1. **model_comparison.csv** - Performance metrics in CSV format
2. **ANALYSIS_REPORT.md** - Comprehensive analysis report

### Example Output
```
outputs/
‚îú‚îÄ‚îÄ confusion_matrix_gru.png
‚îú‚îÄ‚îÄ confusion_matrix_lstm.png
‚îú‚îÄ‚îÄ confusion_matrix_simple_rnn.png
‚îú‚îÄ‚îÄ confusion_matrix_bidirectional_lstm.png
‚îú‚îÄ‚îÄ training_history_gru.png
‚îú‚îÄ‚îÄ training_history_lstm.png
‚îú‚îÄ‚îÄ training_history_simple_rnn.png
‚îú‚îÄ‚îÄ training_history_bidirectional_lstm.png
‚îú‚îÄ‚îÄ model_comparison.png
‚îú‚îÄ‚îÄ roc_curves_comparison.png
‚îú‚îÄ‚îÄ model_comparison.csv
‚îî‚îÄ‚îÄ ANALYSIS_REPORT.md
```

---

## üîç Understanding Results

### Performance Metrics

**Accuracy:** Overall correctness (TP+TN)/(Total)
- Higher is better
- Target: >90% for production

**Precision:** How many predicted malware are actually malware
- TP/(TP+FP)
- High precision = fewer false alarms

**Recall (Sensitivity):** How many actual malware samples were detected
- TP/(TP+FN)
- **Critical for security** - aim for 100%
- Missing malware (FN) is worse than false alarms (FP)

**F1 Score:** Harmonic mean of Precision and Recall
- Balanced metric
- Range: 0-1 (higher is better)

**AUC-ROC:** Area Under ROC Curve
- Model's ability to distinguish classes
- 0.5 = random, 1.0 = perfect
- >0.9 = excellent

### Model Comparison

From our test results:

| Model               | Best For | Pros | Cons |
|---------------------|----------|------|------|
| **GRU**            | Production | Perfect accuracy, fast, efficient | - |
| **Bidirectional LSTM** | High-stakes | Very accurate, robust | Slower, more parameters |
| **Simple RNN**     | Resource-constrained | Smallest, fast, good accuracy | Less sophisticated |
| **LSTM**           | - | Standard choice | Underperformed in our test |

---

## üõ†Ô∏è Troubleshooting

### Common Issues

#### 1. ModuleNotFoundError
```bash
# Make sure virtual environment is activated
source venv/bin/activate

# Reinstall dependencies
pip install -r requirements.txt
```

#### 2. TensorFlow Installation Issues
```bash
# For CPU-only systems
pip install tensorflow-cpu

# For systems with CUDA GPU
pip install tensorflow  # Includes GPU support
```

#### 3. Memory Errors
```python
# Reduce batch size in the script
batch_size=4  # Instead of 8

# Or reduce model complexity
units=32  # Instead of 64
```

#### 4. File Not Found Errors
```bash
# Ensure datasets are in the correct location
ls -la data/

# Check file permissions
chmod 644 data/*.csv data/*.xlsx
```

#### 5. Permission Denied
```bash
# Make setup script executable
chmod +x setup.sh

# Create directories with proper permissions
mkdir -p outputs logs
chmod 755 outputs logs
```

---

## üî¨ Customization & Extension

### Adding New Features

Edit the preprocessing function to include additional features:

```python
def preprocess_data(self, df, test_size=0.3, random_state=42):
    # Add feature engineering here
    df['feature_ratio'] = df['handles_num'] / df['modules_num']
    df['network_activity'] = df['tcp/udp_connections'] + df['dns_requests']
    
    # Continue with existing preprocessing...
```

### Creating Ensemble Models

```python
# After training all models, create ensemble
ensemble_predictions = []
for model_name, model in self.models.items():
    pred = model.predict(self.X_test)
    ensemble_predictions.append(pred)

# Average predictions
final_pred = np.mean(ensemble_predictions, axis=0)
```

### Hyperparameter Tuning

Use scikit-learn's GridSearchCV or RandomizedSearchCV with Keras wrapper:

```python
from tensorflow.keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import GridSearchCV

def create_model(units=64, dropout=0.3):
    # Build and return model
    pass

model = KerasClassifier(build_fn=create_model)
param_grid = {
    'units': [32, 64, 128],
    'dropout': [0.2, 0.3, 0.4],
    'batch_size': [8, 16, 32]
}

grid = GridSearchCV(estimator=model, param_grid=param_grid)
```

---

## üìö Additional Resources

### Documentation
- [TensorFlow RNN Guide](https://www.tensorflow.org/guide/keras/rnn)
- [Keras Sequential Model](https://keras.io/guides/sequential_model/)
- [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)

### Research Papers
- "Fileless Malware Detection Using Machine Learning"
- "Recurrent Neural Networks for Malware Detection"
- "Behavioral Analysis of Memory-Resident Malware"

### Malware Analysis Resources
- [Volatility Framework](https://www.volatilityfoundation.org/) - Memory forensics
- [ANY.RUN](https://any.run/) - Interactive malware sandbox
- [VirusTotal](https://www.virustotal.com/) - Multi-scanner analysis

---

## üêõ Debugging

### Enable Verbose Output

```python
# In train_model(), change verbose parameter
history = model.fit(
    self.X_train, self.y_train,
    validation_split=0.2,
    epochs=epochs,
    batch_size=batch_size,
    callbacks=[early_stop, reduce_lr],
    verbose=1  # Show training progress
)
```

### Save Debug Logs

```python
import logging

logging.basicConfig(
    filename='logs/training.log',
    level=logging.DEBUG,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
```

### Check TensorFlow Installation

```bash
python3 -c "import tensorflow as tf; print(tf.__version__); print('GPU Available:', tf.config.list_physical_devices('GPU'))"
```

---

## üìä Performance Benchmarks

**Test Environment:**
- Ubuntu 22.04 LTS
- Intel Core i7 (8 cores)
- 16GB RAM
- CPU-only (no GPU)

**Training Times:**
- Simple RNN: ~45 seconds
- LSTM: ~35 seconds
- GRU: ~40 seconds
- Bidirectional LSTM: ~60 seconds

**Total Runtime:** ~3-4 minutes for all 4 models

---

## ü§ù Contributing

### Reporting Issues
If you encounter bugs or have feature requests:
1. Check existing issues
2. Provide detailed error messages
3. Include system information (Ubuntu version, Python version)
4. Share sample data if possible (anonymized)

### Improvements
Suggestions for enhancement:
- Support for more RNN architectures (Attention, Transformer)
- Real-time detection mode
- Web interface for visualization
- Model explainability (SHAP, LIME)
- Integration with SIEM systems

---

## üìú License

This project is provided as-is for research and educational purposes. Ensure compliance with your organization's security policies before deploying to production.

---

## üôè Acknowledgments

- TensorFlow/Keras team for the deep learning framework
- Security researchers for fileless malware analysis techniques
- Open-source community for various Python libraries

---

## üìû Support

For questions or issues:
1. Check this README thoroughly
2. Review the ANALYSIS_REPORT.md for detailed methodology
3. Examine the source code comments
4. Test with the example datasets first

---

## üéì Learning Resources

### Getting Started with RNNs
1. **Basics:** Start with Simple RNN to understand fundamentals
2. **Advanced:** Move to LSTM/GRU for better performance
3. **Optimization:** Experiment with bidirectional architectures
4. **Ensemble:** Combine multiple models for robustness

### Best Practices
- Always validate on hold-out test set
- Monitor for overfitting (train vs. validation curves)
- Use early stopping to prevent overfitting
- Normalize/standardize features
- Balance dataset or use class weights
- Cross-validate for robust metrics

---

**Last Updated:** November 2, 2025  
**Version:** 1.0  
**Python:** 3.8+  
**TensorFlow:** 2.13+
